---
title:  "[혼공머신] 5장. 트리 알고리즘"
date:   2024-01-28 18:00:00
categories:
  - 혼공머신
tags:
  - ML
  - DL
---
# 5장. 트리 알고리즘 - 화이트 와인을 찾아라!

## 결정 트리
- 예/아니오에 대한 질문을 이어나가면서 정답을 찾아 학습하는 알고리즘
- 위에서부터 아래로 내려가는 트리 형태
    - 맨 위 노드 : 루트 노드, 맨 아래 노드 : 리프 노드

## 불순도
- 결정 트리가 최적의 질문을 찾기 위한 기준
- 사이킷런은 지니 불순도와 엔트로피 불순도를 제공

## 정보 이득
- 부모 노드와 자식 노드의 불순도 차이
- 정보 이득이 최대화 되도록 학습

## 가지치기
  - 훈련 세트에 과대적합을 막기 위해서 성장을 제한하는 방법

## 교차검증
- 훈련 세트를 여러 폴드로 나눈 다음 한 폴드가 검증역할을 하고 나머지 폴드에서 모델을 훈련 후 모든 폴드에 대해 검증 점수를 얻어 평균하는 방법
- 훈련 세트를 k 부분으로 나눠서 교차 검증을 수행
    - 각 그룹을 (k-1)개의 Training Fold 와 1개의 Validation Fold 로 나눔
- 각 검증 점수의 평균을 최종 검증 점수로 사용
  - ![kfold]({{ site.baseurl }}/images/mldl/kfold.png)

## 확률적 경사 하강법
- 훈련 세트에서 샘플 하나씩 꺼내 손실 함수의 경사를 따라 최적의 모델을 찾는 알고리즘
- 샘플을 하나씩 사용하지 않고 여러 개를 사용하면 미니배치 경사 하강법이 됨
- 한 번에 전체 샘플을 사용하면 배치 경사 하강법
### 에포크
- 확률적 경사 하강법에서 훈련세트를 한번 모두 사용하는 과정
- 일반적으로 경사 하강법은 수십, 수백 번 이상 에포크를 수행
### 손실함수
- 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준
### 비용함수
- 훈련 세트에 있는 모든 샘플에 대한 손실함수의 합
### 로지스틱 손실 함수
- 양성 클래스(타킷 = 1) 일때 소실은 -log(예측 확률)로 계산, 음성 클래스 (타깃=0) 일때 손실은 -log(1-예측확률)로 계산
### 에포크와 과대/과소 적합
- 확률적 경사 하강법을 사용한 모델은 에포크 횟수에 따라 과소적합이나 과대적합이 될 수 있음
- 에포크 횟수가 적으면 과소적합, 너무 많으면 과대적합 문제가 발생
- 훈련세트 점수는 에포크 가 진행될수록 꾸준히 증가하지만 테스트 점수는 어느 순간 감소함
- 과대적합이 시작하기 전에 훈련을 멈추는 것이 조기 종료
